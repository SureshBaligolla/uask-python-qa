{"uid":"b746e8d952e7603","name":"test_simple_chat_responses[desktop-testdata7]","fullName":"tests.test_chat_validation#test_simple_chat_responses","historyId":"35c3411a5ff4e1c84c6d4c8f499e91b2","time":{"start":1761912848939,"stop":1761912917055,"duration":68116},"description":"\n    Validate chatbot responses semantically using OpenAI embeddings.\n    Also validate multilingual behavior: English (LTR) and Arabic (RTL).\n    ","descriptionHtml":"<pre><code>Validate chatbot responses semantically using OpenAI embeddings.\nAlso validate multilingual behavior: English (LTR) and Arabic (RTL).\n</code></pre>\n","status":"failed","statusMessage":"AssertionError: ❌ Similarity too low (0.224) for prompt: simulate_slow_response\nassert 0.224 >= 0.33\n +  where 0.33 = config.SIMILARITY_THRESHOLD_EN","statusTrace":"driver = <selenium.webdriver.chrome.webdriver.WebDriver (session=\"d4751549417a3ca35f5737d822535e55\")>\ntestdata = {'expected_en': 'Loading...', 'prompt_en': 'simulate_slow_response'}\n\n    @pytest.mark.parametrize(\"testdata\", json.load(open(\"test_data/test-data.json\", encoding=\"utf-8\")))\n    def test_simple_chat_responses(driver, testdata):\n        \"\"\"\n        Validate chatbot responses semantically using OpenAI embeddings.\n        Also validate multilingual behavior: English (LTR) and Arabic (RTL).\n        \"\"\"\n        login_page = LoginPage(driver)\n        chat_page = ChatPage(driver)\n    \n        # Step 1: Login\n        assert login_page.is_loaded(), \"❌ Login page did not load properly\"\n        login_page.login()\n        assert chat_page.is_ready(), \"❌ Chatbox not ready after login\"\n    \n        # ============================================================\n        # \uD83C\uDF0D ENGLISH TEST\n        # ============================================================\n        prompt_en = testdata.get(\"prompt_en\")\n        expected_en = testdata.get(\"expected_en\")\n    \n        if prompt_en and expected_en:\n            chat_page.send_message(prompt_en)\n            actual_en = chat_page.wait_for_ai_response(timeout=30)\n    \n            # Retry once if response looks truncated or empty\n            if not actual_en or len(actual_en.strip()) < 50:\n                print(\"⚠️ English response seems incomplete, retrying...\")\n                time.sleep(1)\n                extra = chat_page.wait_for_ai_response(timeout=10)\n                if extra and len(extra) > len(actual_en or \"\"):\n                    actual_en = extra\n    \n            # Fail fast if empty\n            assert actual_en and actual_en.strip(), \"❌ No AI response captured for English prompt\"\n    \n            similarity_en = openai_validator.calculate_similarity(expected_en, actual_en)\n    \n            print(f\"\\n\uD83C\uDF0D English Prompt: {prompt_en}\")\n            print(f\"Expected: {expected_en}\")\n            print(f\"Actual ({len(actual_en)} chars): {actual_en}\")\n            print(f\"\uD83D\uDD0D Similarity Score: {similarity_en}\")\n    \n            # ✅ Attach English results to Allure report\n            with allure.step(\"Attach English response details\"):\n                allure.attach(prompt_en, name=\"English Prompt\", attachment_type=allure.attachment_type.TEXT)\n                allure.attach(expected_en, name=\"Expected English Response\", attachment_type=allure.attachment_type.TEXT)\n                allure.attach(actual_en, name=\"Actual English Response\", attachment_type=allure.attachment_type.TEXT)\n                allure.attach(str(round(similarity_en, 3)), name=\"English Similarity Score\", attachment_type=allure.attachment_type.TEXT)\n    \n                # Screenshot on low similarity\n                if similarity_en < config.SIMILARITY_THRESHOLD_EN:\n                    try:\n                        allure.attach(driver.get_screenshot_as_png(), name=\"English Screenshot\", attachment_type=allure.attachment_type.PNG)\n                    except Exception:\n                        pass\n    \n            # ✅ Semantic validation\n>           assert similarity_en >= config.SIMILARITY_THRESHOLD_EN, (\n                f\"❌ Similarity too low ({similarity_en:.3f}) for prompt: {prompt_en}\"\n            )\nE           AssertionError: ❌ Similarity too low (0.224) for prompt: simulate_slow_response\nE           assert 0.224 >= 0.33\nE            +  where 0.33 = config.SIMILARITY_THRESHOLD_EN\n\ntests/test_chat_validation.py:254: AssertionError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[{"name":"driver","time":{"start":1761912391632,"stop":1761912394550,"duration":2918},"status":"passed","steps":[],"attachments":[],"parameters":[],"stepsCount":0,"hasContent":false,"attachmentStep":false,"shouldDisplayMessage":false,"attachmentsCount":0}],"testStage":{"description":"\n    Validate chatbot responses semantically using OpenAI embeddings.\n    Also validate multilingual behavior: English (LTR) and Arabic (RTL).\n    ","status":"failed","statusMessage":"AssertionError: ❌ Similarity too low (0.224) for prompt: simulate_slow_response\nassert 0.224 >= 0.33\n +  where 0.33 = config.SIMILARITY_THRESHOLD_EN","statusTrace":"driver = <selenium.webdriver.chrome.webdriver.WebDriver (session=\"d4751549417a3ca35f5737d822535e55\")>\ntestdata = {'expected_en': 'Loading...', 'prompt_en': 'simulate_slow_response'}\n\n    @pytest.mark.parametrize(\"testdata\", json.load(open(\"test_data/test-data.json\", encoding=\"utf-8\")))\n    def test_simple_chat_responses(driver, testdata):\n        \"\"\"\n        Validate chatbot responses semantically using OpenAI embeddings.\n        Also validate multilingual behavior: English (LTR) and Arabic (RTL).\n        \"\"\"\n        login_page = LoginPage(driver)\n        chat_page = ChatPage(driver)\n    \n        # Step 1: Login\n        assert login_page.is_loaded(), \"❌ Login page did not load properly\"\n        login_page.login()\n        assert chat_page.is_ready(), \"❌ Chatbox not ready after login\"\n    \n        # ============================================================\n        # \uD83C\uDF0D ENGLISH TEST\n        # ============================================================\n        prompt_en = testdata.get(\"prompt_en\")\n        expected_en = testdata.get(\"expected_en\")\n    \n        if prompt_en and expected_en:\n            chat_page.send_message(prompt_en)\n            actual_en = chat_page.wait_for_ai_response(timeout=30)\n    \n            # Retry once if response looks truncated or empty\n            if not actual_en or len(actual_en.strip()) < 50:\n                print(\"⚠️ English response seems incomplete, retrying...\")\n                time.sleep(1)\n                extra = chat_page.wait_for_ai_response(timeout=10)\n                if extra and len(extra) > len(actual_en or \"\"):\n                    actual_en = extra\n    \n            # Fail fast if empty\n            assert actual_en and actual_en.strip(), \"❌ No AI response captured for English prompt\"\n    \n            similarity_en = openai_validator.calculate_similarity(expected_en, actual_en)\n    \n            print(f\"\\n\uD83C\uDF0D English Prompt: {prompt_en}\")\n            print(f\"Expected: {expected_en}\")\n            print(f\"Actual ({len(actual_en)} chars): {actual_en}\")\n            print(f\"\uD83D\uDD0D Similarity Score: {similarity_en}\")\n    \n            # ✅ Attach English results to Allure report\n            with allure.step(\"Attach English response details\"):\n                allure.attach(prompt_en, name=\"English Prompt\", attachment_type=allure.attachment_type.TEXT)\n                allure.attach(expected_en, name=\"Expected English Response\", attachment_type=allure.attachment_type.TEXT)\n                allure.attach(actual_en, name=\"Actual English Response\", attachment_type=allure.attachment_type.TEXT)\n                allure.attach(str(round(similarity_en, 3)), name=\"English Similarity Score\", attachment_type=allure.attachment_type.TEXT)\n    \n                # Screenshot on low similarity\n                if similarity_en < config.SIMILARITY_THRESHOLD_EN:\n                    try:\n                        allure.attach(driver.get_screenshot_as_png(), name=\"English Screenshot\", attachment_type=allure.attachment_type.PNG)\n                    except Exception:\n                        pass\n    \n            # ✅ Semantic validation\n>           assert similarity_en >= config.SIMILARITY_THRESHOLD_EN, (\n                f\"❌ Similarity too low ({similarity_en:.3f}) for prompt: {prompt_en}\"\n            )\nE           AssertionError: ❌ Similarity too low (0.224) for prompt: simulate_slow_response\nE           assert 0.224 >= 0.33\nE            +  where 0.33 = config.SIMILARITY_THRESHOLD_EN\n\ntests/test_chat_validation.py:254: AssertionError","steps":[{"name":"Attach English response details","time":{"start":1761912916875,"stop":1761912917054,"duration":179},"status":"passed","steps":[],"attachments":[{"uid":"18d2be3f394762c0","name":"English Prompt","source":"18d2be3f394762c0.txt","type":"text/plain","size":22},{"uid":"982863dbc1f93351","name":"Expected English Response","source":"982863dbc1f93351.txt","type":"text/plain","size":10},{"uid":"1fa0d1f23ccc92f0","name":"Actual English Response","source":"1fa0d1f23ccc92f0.txt","type":"text/plain","size":89},{"uid":"89092b41c68b1ef1","name":"English Similarity Score","source":"89092b41c68b1ef1.txt","type":"text/plain","size":5},{"uid":"36cea57c7e8f6092","name":"English Screenshot","source":"36cea57c7e8f6092.png","type":"image/png","size":144635}],"parameters":[],"stepsCount":0,"hasContent":true,"attachmentStep":false,"shouldDisplayMessage":false,"attachmentsCount":5}],"attachments":[{"uid":"21c66e51b5fa1742","name":"log","source":"21c66e51b5fa1742.txt","type":"text/plain","size":227},{"uid":"268a6d579e6f5225","name":"stdout","source":"268a6d579e6f5225.txt","type":"text/plain","size":2188}],"parameters":[],"stepsCount":1,"hasContent":true,"attachmentStep":false,"shouldDisplayMessage":true,"attachmentsCount":7},"afterStages":[{"name":"driver::0","time":{"start":1761913619561,"stop":1761913619711,"duration":150},"status":"passed","steps":[],"attachments":[],"parameters":[],"stepsCount":0,"hasContent":false,"attachmentStep":false,"shouldDisplayMessage":false,"attachmentsCount":0}],"labels":[{"name":"parentSuite","value":"tests"},{"name":"suite","value":"test_chat_validation"},{"name":"host","value":"Hemanth.local"},{"name":"thread","value":"25458-MainThread"},{"name":"framework","value":"pytest"},{"name":"language","value":"cpython3"},{"name":"package","value":"tests.test_chat_validation"},{"name":"resultFormat","value":"allure2"}],"parameters":[{"name":"driver","value":"'desktop'"},{"name":"testdata","value":"{'prompt_en': 'simulate_slow_response', 'expected_en': 'Loading...'}"}],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"Product defects","matchedStatuses":[]}],"tags":[]},"source":"b746e8d952e7603.json","parameterValues":["'desktop'","{'prompt_en': 'simulate_slow_response', 'expected_en': 'Loading...'}"]}