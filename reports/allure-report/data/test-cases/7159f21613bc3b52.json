{"uid":"7159f21613bc3b52","name":"test_simple_chat_responses[mobile-testdata7]","fullName":"tests.test_chat_validation#test_simple_chat_responses","historyId":"27e166dabf8837f7fd0cf4c1b1f98b31","time":{"start":1761914636444,"stop":1761914741162,"duration":104718},"description":"\n    Validate chatbot responses semantically using OpenAI embeddings.\n    Also validate multilingual behavior: English (LTR) and Arabic (RTL).\n    ","descriptionHtml":"<pre><code>Validate chatbot responses semantically using OpenAI embeddings.\nAlso validate multilingual behavior: English (LTR) and Arabic (RTL).\n</code></pre>\n","status":"failed","statusMessage":"AssertionError: ❌ Similarity too low (0.244) for prompt: simulate_slow_response\nassert 0.244 >= 0.33\n +  where 0.33 = config.SIMILARITY_THRESHOLD_EN","statusTrace":"driver = <selenium.webdriver.chrome.webdriver.WebDriver (session=\"1790e15ff0813a8eeb230d92a3bae72d\")>\ntestdata = {'expected_en': 'Loading...', 'prompt_en': 'simulate_slow_response'}\n\n    @pytest.mark.parametrize(\"testdata\", json.load(open(\"test_data/test-data.json\", encoding=\"utf-8\")))\n    def test_simple_chat_responses(driver, testdata):\n        \"\"\"\n        Validate chatbot responses semantically using OpenAI embeddings.\n        Also validate multilingual behavior: English (LTR) and Arabic (RTL).\n        \"\"\"\n        login_page = LoginPage(driver)\n        chat_page = ChatPage(driver)\n    \n        # Step 1: Login\n        assert login_page.is_loaded(), \"❌ Login page did not load properly\"\n        login_page.login()\n        assert chat_page.is_ready(), \"❌ Chatbox not ready after login\"\n    \n        # ============================================================\n        # \uD83C\uDF0D ENGLISH TEST\n        # ============================================================\n        prompt_en = testdata.get(\"prompt_en\")\n        expected_en = testdata.get(\"expected_en\")\n    \n        if prompt_en and expected_en:\n            chat_page.send_message(prompt_en)\n            actual_en = chat_page.wait_for_ai_response(timeout=30)\n    \n            # Retry once if response looks truncated or empty\n            if not actual_en or len(actual_en.strip()) < 50:\n                print(\"⚠️ English response seems incomplete, retrying...\")\n                time.sleep(1)\n                extra = chat_page.wait_for_ai_response(timeout=10)\n                if extra and len(extra) > len(actual_en or \"\"):\n                    actual_en = extra\n    \n            # Fail fast if empty\n            assert actual_en and actual_en.strip(), \"❌ No AI response captured for English prompt\"\n    \n            similarity_en = openai_validator.calculate_similarity(expected_en, actual_en)\n    \n            print(f\"\\n\uD83C\uDF0D English Prompt: {prompt_en}\")\n            print(f\"Expected: {expected_en}\")\n            print(f\"Actual ({len(actual_en)} chars): {actual_en}\")\n            print(f\"\uD83D\uDD0D Similarity Score: {similarity_en}\")\n    \n            # ✅ Attach English results to Allure report\n            with allure.step(\"Attach English response details\"):\n                allure.attach(prompt_en, name=\"English Prompt\", attachment_type=allure.attachment_type.TEXT)\n                allure.attach(expected_en, name=\"Expected English Response\", attachment_type=allure.attachment_type.TEXT)\n                allure.attach(actual_en, name=\"Actual English Response\", attachment_type=allure.attachment_type.TEXT)\n                allure.attach(str(round(similarity_en, 3)), name=\"English Similarity Score\", attachment_type=allure.attachment_type.TEXT)\n    \n                # Screenshot on low similarity\n                if similarity_en < config.SIMILARITY_THRESHOLD_EN:\n                    try:\n                        allure.attach(driver.get_screenshot_as_png(), name=\"English Screenshot\", attachment_type=allure.attachment_type.PNG)\n                    except Exception:\n                        pass\n    \n            # ✅ Semantic validation\n>           assert similarity_en >= config.SIMILARITY_THRESHOLD_EN, (\n                f\"❌ Similarity too low ({similarity_en:.3f}) for prompt: {prompt_en}\"\n            )\nE           AssertionError: ❌ Similarity too low (0.244) for prompt: simulate_slow_response\nE           assert 0.244 >= 0.33\nE            +  where 0.33 = config.SIMILARITY_THRESHOLD_EN\n\ntests/test_chat_validation.py:254: AssertionError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[{"name":"driver","time":{"start":1761913619712,"stop":1761913623271,"duration":3559},"status":"passed","steps":[],"attachments":[],"parameters":[],"stepsCount":0,"hasContent":false,"attachmentStep":false,"shouldDisplayMessage":false,"attachmentsCount":0}],"testStage":{"description":"\n    Validate chatbot responses semantically using OpenAI embeddings.\n    Also validate multilingual behavior: English (LTR) and Arabic (RTL).\n    ","status":"failed","statusMessage":"AssertionError: ❌ Similarity too low (0.244) for prompt: simulate_slow_response\nassert 0.244 >= 0.33\n +  where 0.33 = config.SIMILARITY_THRESHOLD_EN","statusTrace":"driver = <selenium.webdriver.chrome.webdriver.WebDriver (session=\"1790e15ff0813a8eeb230d92a3bae72d\")>\ntestdata = {'expected_en': 'Loading...', 'prompt_en': 'simulate_slow_response'}\n\n    @pytest.mark.parametrize(\"testdata\", json.load(open(\"test_data/test-data.json\", encoding=\"utf-8\")))\n    def test_simple_chat_responses(driver, testdata):\n        \"\"\"\n        Validate chatbot responses semantically using OpenAI embeddings.\n        Also validate multilingual behavior: English (LTR) and Arabic (RTL).\n        \"\"\"\n        login_page = LoginPage(driver)\n        chat_page = ChatPage(driver)\n    \n        # Step 1: Login\n        assert login_page.is_loaded(), \"❌ Login page did not load properly\"\n        login_page.login()\n        assert chat_page.is_ready(), \"❌ Chatbox not ready after login\"\n    \n        # ============================================================\n        # \uD83C\uDF0D ENGLISH TEST\n        # ============================================================\n        prompt_en = testdata.get(\"prompt_en\")\n        expected_en = testdata.get(\"expected_en\")\n    \n        if prompt_en and expected_en:\n            chat_page.send_message(prompt_en)\n            actual_en = chat_page.wait_for_ai_response(timeout=30)\n    \n            # Retry once if response looks truncated or empty\n            if not actual_en or len(actual_en.strip()) < 50:\n                print(\"⚠️ English response seems incomplete, retrying...\")\n                time.sleep(1)\n                extra = chat_page.wait_for_ai_response(timeout=10)\n                if extra and len(extra) > len(actual_en or \"\"):\n                    actual_en = extra\n    \n            # Fail fast if empty\n            assert actual_en and actual_en.strip(), \"❌ No AI response captured for English prompt\"\n    \n            similarity_en = openai_validator.calculate_similarity(expected_en, actual_en)\n    \n            print(f\"\\n\uD83C\uDF0D English Prompt: {prompt_en}\")\n            print(f\"Expected: {expected_en}\")\n            print(f\"Actual ({len(actual_en)} chars): {actual_en}\")\n            print(f\"\uD83D\uDD0D Similarity Score: {similarity_en}\")\n    \n            # ✅ Attach English results to Allure report\n            with allure.step(\"Attach English response details\"):\n                allure.attach(prompt_en, name=\"English Prompt\", attachment_type=allure.attachment_type.TEXT)\n                allure.attach(expected_en, name=\"Expected English Response\", attachment_type=allure.attachment_type.TEXT)\n                allure.attach(actual_en, name=\"Actual English Response\", attachment_type=allure.attachment_type.TEXT)\n                allure.attach(str(round(similarity_en, 3)), name=\"English Similarity Score\", attachment_type=allure.attachment_type.TEXT)\n    \n                # Screenshot on low similarity\n                if similarity_en < config.SIMILARITY_THRESHOLD_EN:\n                    try:\n                        allure.attach(driver.get_screenshot_as_png(), name=\"English Screenshot\", attachment_type=allure.attachment_type.PNG)\n                    except Exception:\n                        pass\n    \n            # ✅ Semantic validation\n>           assert similarity_en >= config.SIMILARITY_THRESHOLD_EN, (\n                f\"❌ Similarity too low ({similarity_en:.3f}) for prompt: {prompt_en}\"\n            )\nE           AssertionError: ❌ Similarity too low (0.244) for prompt: simulate_slow_response\nE           assert 0.244 >= 0.33\nE            +  where 0.33 = config.SIMILARITY_THRESHOLD_EN\n\ntests/test_chat_validation.py:254: AssertionError","steps":[{"name":"Attach English response details","time":{"start":1761914740974,"stop":1761914741161,"duration":187},"status":"passed","steps":[],"attachments":[{"uid":"bcd8a3c48114cc3a","name":"English Prompt","source":"bcd8a3c48114cc3a.txt","type":"text/plain","size":22},{"uid":"6345945fff94705b","name":"Expected English Response","source":"6345945fff94705b.txt","type":"text/plain","size":10},{"uid":"f334ea263e52311c","name":"Actual English Response","source":"f334ea263e52311c.txt","type":"text/plain","size":87},{"uid":"c05bcdc6a75e02ee","name":"English Similarity Score","source":"c05bcdc6a75e02ee.txt","type":"text/plain","size":5},{"uid":"aca0ea9d3e96056c","name":"English Screenshot","source":"aca0ea9d3e96056c.png","type":"image/png","size":150233}],"parameters":[],"stepsCount":0,"hasContent":true,"attachmentStep":false,"shouldDisplayMessage":false,"attachmentsCount":5}],"attachments":[{"uid":"5e5a80e0a4e72b67","name":"log","source":"5e5a80e0a4e72b67.txt","type":"text/plain","size":227},{"uid":"d05b162674fed0b3","name":"stdout","source":"d05b162674fed0b3.txt","type":"text/plain","size":2214}],"parameters":[],"stepsCount":1,"hasContent":true,"attachmentStep":false,"shouldDisplayMessage":true,"attachmentsCount":7},"afterStages":[{"name":"driver::0","time":{"start":1761915392975,"stop":1761915392979,"duration":4},"status":"passed","steps":[],"attachments":[],"parameters":[],"stepsCount":0,"hasContent":false,"attachmentStep":false,"shouldDisplayMessage":false,"attachmentsCount":0}],"labels":[{"name":"parentSuite","value":"tests"},{"name":"suite","value":"test_chat_validation"},{"name":"host","value":"Hemanth.local"},{"name":"thread","value":"25458-MainThread"},{"name":"framework","value":"pytest"},{"name":"language","value":"cpython3"},{"name":"package","value":"tests.test_chat_validation"},{"name":"resultFormat","value":"allure2"}],"parameters":[{"name":"driver","value":"'mobile'"},{"name":"testdata","value":"{'prompt_en': 'simulate_slow_response', 'expected_en': 'Loading...'}"}],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"Product defects","matchedStatuses":[]}],"tags":[]},"source":"7159f21613bc3b52.json","parameterValues":["'mobile'","{'prompt_en': 'simulate_slow_response', 'expected_en': 'Loading...'}"]}