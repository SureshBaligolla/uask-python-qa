# QA Automation Case Study â€” U-Ask Chatbot (GovGPT)

### ðŸ‘¤ Author
**Suresh Baligolla**

---

## ðŸ“˜ Overview
Automated end-to-end testing framework for the UAE Governmentâ€™s **U-Ask (GovGPT)** chatbot.

Validates:
- Chatbot UI functionality (load, send, response, clear, scroll)
- AI/ML semantic correctness using OpenAI embeddings
- Multilingual support (English & Arabic)
- Security input sanitization & malicious prompt handling

---

## ðŸ§± Project Structure
uask-python-qa/
â”‚
â”œâ”€â”€ tests/                       # All test cases
â”‚   â””â”€â”€ test_chat_validation.py  # Semantic + security validation
â”‚   â””â”€â”€ test_layout_direction.py # LTR/RTL direction tests (optional)
â”‚
â”œâ”€â”€ pages/                       # Page Object Model (POM)
â”‚   â”œâ”€â”€ login_page.py            # Login functionality
â”‚   â””â”€â”€ chat_page.py             # Chat screen actions and message handling
â”‚
â”œâ”€â”€ utils/                       
â”‚   â”œâ”€â”€ config.py                # Global constants, URLs, and thresholds
â”‚   â””â”€â”€ openai_validator.py      # Embedding-based semantic scoring
â”‚
â”œâ”€â”€ test_data/
â”‚   â””â”€â”€ test-data.json           # Prompts and expected responses
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ test_report.html         # Pytest HTML output
â”‚   â””â”€â”€ allure-results/          # Allure result files
â”‚
â”œâ”€â”€ screenshots/                 # Captured images during test runs
â”œâ”€â”€ conftest.py                  # PyTest driver fixture (setup + teardown)
â”œâ”€â”€ requirements.txt             # Dependencies
â””â”€â”€ README.md


1.Install dependencies
pip install -r requirements.txt

2.Set your OpenAI API key
export OPENAI_API_KEY=your_api_key_here

3.Run all tests
pytest -v --alluredir=reports/allure-results

4.View live Allure report
allure serve reports/allure-results

Delete allure reporst
rm -rf reports/allure-results reports/allure-report

run all : pytest -v --alluredir=reports/allure-results       
allure serve reports/allure-results 


5.Language Configuration

The chatbot supports both English and Arabic test data.

To configure:

Open test_data/test-data.json

Add your prompts and expected responses.

Example:

[
  {
    "prompt_en": "Hello",
    "expected_en": "Hello! How can I assist you today?",
    "prompt_ar": "Ù…Ø±Ø­Ø¨Ø§",
    "expected_ar": "Ù…Ø±Ø­Ø¨Ù‹Ø§! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"
  }
]

6.Semantic Validation (AI/ML)

Instead of keyword matching, this project uses OpenAI text-embedding-3-small to evaluate response meaning.

Expected and actual responses are embedded as numerical vectors.

Cosine similarity measures how close they are in meaning.

A similarity threshold (default 0.6) determines a pass/fail.

similarity = openai_validator.calculate_similarity(expected, actual)
assert similarity >= config.SIMILARITY_THRESHOLD


Benefits:

Robust to paraphrases and synonyms

Works across multiple languages

Fewer false failures compared to string matching



Maintainer: Suresh Baligolla


Run offline reports

cd reports/allure-report
python3 -m http.server 8000











